{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f66aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the important libraries to create the RandomForestClassifier Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data set\n",
    "\n",
    "Data = pd.read_csv(r\"C:\\Users\\Vinoth\\Desktop\\HOPE AI\\Machine Learning\\Classification_Models\\Chronic Kidney Disease Prediction Assignment\\Dataset\\CKD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c16483",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ace952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check total number of rows and columns \n",
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the dataset info \n",
    "Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b2c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the description of data set\n",
    "Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0da704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check if the data set has NA values\n",
    "Data[Data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecaa944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check if the data set has Null values\n",
    "Data[Data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check how many classes are there in the target variable \"Classification\"\n",
    "Data.classification.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08be685",
   "metadata": {},
   "source": [
    "# From above output we got to know that there are 250 records in \"Yes\" class and 150 records in \"No\" class. so its called as imbalanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f27325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets upsample the \"No\" records to match with \"Yes\" records\n",
    "Data_No = Data[Data[\"classification\"]==\"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "samples_index = random.sample(range(150),99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77abf41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_No_final = Data_No.iloc[samples_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_No_final.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb17268",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_No_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbe5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data.append(Data_No_final,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.classification.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd242f",
   "metadata": {},
   "source": [
    "# From above output we have upsampled the \"No\" class counts to match with \"Yes\" counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fdc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets convert the nominal categoty columns to numerical columns using one-hot-encoding via pandas get_dummies method\n",
    "\n",
    "Data = pd.get_dummies(Data,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1dc92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cdb120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets seperate the dependent and independent variables\n",
    "dependent = Data[['classification_yes']]\n",
    "independent = Data[['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
    "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
    "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
    "       'appet_yes', 'pe_yes', 'ane_yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets spli the data to trai  and test set\n",
    "\n",
    "X_Train,X_Test,Y_Train,Y_Test = train_test_split(independent,dependent,random_state=0,test_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters \n",
    "Model_Params = {'n_estimators':[i for i in range(1,500,100) ],\"criterion\":['gini','entropy','log_loss'],\"max_depth\":[i for i in range(1,int(len(Data.columns.to_list())/2))],\n",
    "               'min_samples_split':[i for i in np.arange(0.1,1.0,0.3)],'min_samples_leaf':[i for i in np.arange(0.1,1.0,0.3)],\n",
    "               'max_features':['auto','sqrt','log2'],'min_impurity_decrease':[i for i in np.arange(0.1,1.0,0.3)],'ccp_alpha':[0.00001,0.001,0.1],'n_jobs':[-1],'warm_start':[True],\n",
    "                'class_weight':['balanced','balanced_subsample']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb49df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a model now using the Gridsearch CV\n",
    "\n",
    "RFC_Model_Creation = GridSearchCV(RandomForestClassifier(),Model_Params,n_jobs=-1,scoring={\"roc_auc_score\":'roc_auc','f1_weighted_score':'f1_weighted'},\n",
    "                                            refit='roc_auc_score',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9844bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_Model_Creation.fit(X_Train,Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best parameter that has givem high performance scores\n",
    "RFC_Model_Creation.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best score for the above parameters\n",
    "RFC_Model_Creation.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e647f5",
   "metadata": {},
   "source": [
    "# Since there are lot of failures in the gridsearch CV results so the entries will be NA. so we don't need those entries to be saved as it may confuse us in future so we are removing those NA entries and have only the valid entries of grid search CV results saved and used for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating as data frame to save the GridSearch CV results\n",
    "CV_Output = pd.DataFrame.from_dict(RFC_Model_Creation.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa652922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the entries count\n",
    "CV_Output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b189d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Data frame that has valid entries in it\n",
    "CV_Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets save the grid search CV results to the csv file\n",
    "CV_Output.to_csv(r\"C:\\Users\\Vinoth\\Desktop\\HOPE AI\\Machine Learning\\Classification_Models\\Chronic Kidney Disease Prediction Assignment\\Grid Serach CV Results\\RFC_GridSerachCV_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test the model with best parameter that we have got agains the test data and check the performance\n",
    "\n",
    "Y_Predicted = RFC_Model_Creation.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0befef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the confusion matrix for the above predicted against the actual results\n",
    "confusion_matrix(Y_Predicted,Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be568e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the classification test report for the predicted against the actual results\n",
    "print(classification_report(Y_Predicted,Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f808cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_Model_Creation.predict_proba(X_Test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3682c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the roc_auc_score results for the predicted against the actual results\n",
    "roc_auc_score(Y_Test,RFC_Model_Creation.predict_proba(X_Test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow we can see our auc score is 100 percent and weighted f1 score is also 93 percent lets save out model\n",
    "import pickle\n",
    "pickle.dump(RFC_Model_Creation,open(r'C:\\Users\\Vinoth\\Desktop\\HOPE AI\\Machine Learning\\Classification_Models\\Chronic Kidney Disease Prediction Assignment\\Final Model\\RFC_Final_Model.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399072fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load and test our model\n",
    "def Final_model_prod(model,columns,stdscaler='None'):\n",
    "    query_values=[]\n",
    "    for col_idx in range(0,len(columns)-1):\n",
    "        query_values.append(float(input(\"Please enter valid {}: \\n Note: If this is a boolean parameter please provide values as 1 for 'yes' and 0 for 'No' \".format(columns[col_idx]))))\n",
    "    pred_class=model.predict(stdscaler.transform([query_values]))\n",
    "    \n",
    "    if pred_class==0:\n",
    "        print (\"This patient doesn't have Chronic Kidney Disorder\")\n",
    "    else:\n",
    "        print (\"This patient have Chronic Kidney Disorder Please proceed proper medication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900ea4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "import pickle\n",
    "Final_model= pickle.load(open(r\"C:\\Users\\Vinoth\\Desktop\\HOPE AI\\Machine Learning\\Classification_Models\\Chronic Kidney Disease Prediction Assignment\\Final Model\\RFC_Final_Model.sav\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4463eebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.001,\n",
       " 'class_weight': 'balanced',\n",
       " 'criterion': 'log_loss',\n",
       " 'max_depth': 1,\n",
       " 'max_features': 'log2',\n",
       " 'min_impurity_decrease': 0.1,\n",
       " 'min_samples_leaf': 0.1,\n",
       " 'min_samples_split': 0.1,\n",
       " 'n_estimators': 101,\n",
       " 'n_jobs': -1,\n",
       " 'warm_start': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd92fa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984923337335406"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f3b2c",
   "metadata": {},
   "source": [
    "# here the scaler is the varaible that we have used for standardising the independent variables so we should use the same variable here  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the final model\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "Final_model_prod(Final_model,Data.columns.to_list(),scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the final model\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "Final_model_prod(Final_model,Data.columns.to_list(),scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ddf2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
